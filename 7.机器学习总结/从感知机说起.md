## Perceptron 感知机

### Perceptron
直观解释,超平面分隔
误分类,损失函数的定义
最优解不唯一(不能再深入判断不同解的优劣),思考可不可以比较不同解之间的优劣呢?
### LR(Logistic Regression)
sigmoid→其实就是
$sigmoid(\boldsymbol{w}^T\boldsymbol{x})<0.5$ 和 $sigmoid(\boldsymbol{w}^T\boldsymbol{x})>0.5$ 等价于 $\boldsymbol{w}^T\boldsymbol{x}<0$和$\boldsymbol{w}^T\boldsymbol{x}>0$
离散的分类问题,为什么要引入一个连续函数从而变成回归问题?
1. 可以给出一个概率估计.两个样本虽然被判定属于同一类,但是它们的确信度可能并不一样.sigmoid函数值可以作为一个概率,确信度的参考.
2. 感知机的不足,最优解不唯一(不能再深入判断不同解的优劣),本质是感知机的激活函数(阶跃函数)不是连续的?用它来描述的数学模型不是一个好的模型(开放性的?非闭合的问题?非凸?).
3. 激活函数 从 阶跃函数→连续函数,而且sigmoid的极大似然估计得到的损失函数也是连续的,而且是凸的(很好的性质)最优解唯一(对应凸函数的极值点),可以用通用的优化方法来求解,可以使用一些优化方法,梯度下降,牛顿法来求最优解等.

sigmoid函数的特点,若$\sigma=sigmoid(z)$
$$
    \begin{aligned}
        \sigma'=\sigma(1-\sigma)\\
        \ln\frac{\sigma}{1-\sigma}=z
    \end{aligned}
$$

$\sigma$ 被视为作为正例的可能性, $\frac{\sigma}{1-\sigma}$ 被称为几率(odds),
而 $\ln\frac{\sigma}{1-\sigma}$ 被称为对数几率(log odds,或者logit)

其他激活函数

双曲正切函数
$$
    tanh(z)=\frac{sinh(z)}{cosh(z)}=\frac{e^z-e^{-z}}{e^z+e^{-z}}
$$

反正切函数
$$
    tan^{-1}(z)
$$

线性整流函数(Rectified Linear Unit, ReLU),又称修正线性单元
$$
    max(0, z)
$$

为什么要提出这些激活函数?

多分类问题

softmax

### SVM(Support Vector Machine)
实质是什么?带约束的不等式优化问题,而且是凸优化问题(二次规划)最优解唯一.
可以用拉格朗日对偶和拉格朗日数乘法推导出KKT条件.
边界→支持向量
带约束的不等式优化问题
1. 如果最优解在边界内部,等价于凸优化,而且是极值点.$\lambda_i\not ={0}, g'_i(x)=0$
2. 如果最优解在边界上,等价于等式优化,即可以用拉格朗日数乘法求解.$\lambda_i=0, g'_i(x)\not ={0}$
3. 总之:$\lambda_ig'_i(x)=0$

### MLP(Multi Layer Perceptron)
就是ANN


非线性问题
异或问题→双层感知机

再提激活函数

### BP

### DNN(Deep Neural Network)