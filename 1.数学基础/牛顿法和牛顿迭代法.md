## 牛顿法和牛顿迭代法

牛顿法,大致的思想是用泰勒公式的前几项来代替原来的函数,然后对函数进行求解和优化.牛顿法和应用于最优化的牛顿法稍微有些差别.

### 牛顿法
牛顿法用来迭代的求解一个方程的解,原理如下:
对于一个函数f(x),它的泰勒级数展开式是这样的
$$
    f(x)=f(x_0)+f'(x_0)(x−x_0)+\frac{1}{2}f''(x_0)(x−x_0)^2+...+\frac{1}{n!}fn(x_0)(x−x_0)^n
$$
当使用牛顿法来求一个方程解的时候,它使用泰勒级数前两项来代替这个函数,即用$ϕ(x)$代替$f(x)$,其中:
$$
    ϕ(x)=f(x_0)+f'(x_0)(x−x_0)
$$
令$ϕ(x)=0$,则 
$$
    x=x_0−\frac{f(x_0)}{f'(x_0)}
$$
所以,牛顿法的迭代公式是
$$
    x_{n+1}=x_n−\frac{f(x_n)}{f'(x_n)}
$$

### 牛顿法求解n的平方根
求解n的平方根,其实是求方程$x^2−n=0$的解
利用上面的公式可以得到:
$$
    x_{i+1}=x_i−\frac{x_i^2−n}{2x_i}=\frac{1}{2}(x_i+\frac{n}{x_i})
$$
编程的时候核心的代码是:`x = (x + n/x)/2`

### 应用于最优化的牛顿法
应用于最优化的牛顿法是以迭代的方式来求解一个函数的最优解,常用的优化方法还有**梯度下降法**.
取泰勒展开式的二次项,即用$ϕ(x)$来代替$f(x)$:
$$
    ϕ(x)=f(x_0)+f'(x_0)(x−x_0)+\frac{1}{2}f''(x_0)(x−x_0)^2
$$
最优点的选择是$ϕ'(x)=0$的点,对上式求导

$$
    ϕ'(x)=f'(x_0)+f''(x_0)(x−x_0)
$$
令$ϕ'(x)=0$,则
$$
    x=x_0−\frac{f'(x_0)}{f''(x_0)}
$$
所以,最优化的牛顿迭代公式是

$$
    x_{n+1}=x_n−\frac{f'(x_n)}{f''(x_n)}
$$
### 高维下的牛顿优化方法
在高维下
$$
    ϕ(x)=f(x_0)+∇f(x_0)^T(x−x_0)+\frac{1}{2}(x−x_0)^T∇^2f(x_0)(x−x_0)
$$
求$∇ϕ(x)$,并令它等于0,则公式变为了
$$
    ∇f(x_0)+∇^2f(x_0)(x−x_0)=0
$$
即
$$
    x=x_0−∇^2f(x_0)^{−1}∇f(x_0)
$$
所以,迭代公式变为
$$
    x_{n+1}=x_n−∇^2f(x_n)^{−1}∇f(x_n)
$$
其中:
$x_{n+1},x_n$都是$N\times 1$维的矢量.
$∇^2f(x_n)$是**Hessien矩阵**,$∇^2f(x_n)^{−1}$是Hessien矩阵的**逆矩阵**,它们都是是$N\times N$维的.
$∇f(x_n)$是 $f(x)$ 的导数,是$N\times 1$维的.

和梯度下降法相比,在使用牛顿迭代法进行优化的时候,需要求**Hessien矩阵的逆矩阵**,这个**开销是很大**的.