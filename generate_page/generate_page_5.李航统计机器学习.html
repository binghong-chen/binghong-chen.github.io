<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第1章 统计学习方法概论.md">第1章 统计学习方法概论</div>
    <div class="preview">
        <p>本章简要叙述统计学习方法的一些基本概念.这是对全书内容的概括,也是全书内容的基础.首先叙述统计学习的定义,研究对象与方法;然后叙述统计学习,这是本书的主要内容;接着提出统计学习方法的三要素:模型,策略,算法;介绍模型选择,包括正则化,交叉验证与学习的泛化能力;介绍生成模型和判别模型;最后介绍监督学习方法的应用:分类问题,标注问题和回归问题.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第2章 感知机.md">第2章 感知机</div>
    <div class="preview">
        <p>感知机(perceptron)是二分类的线性分类模型,其输入为实例的特征向量,输出位实例的类别,取+1和-1二值.感知机对应于输入空间(特征空间)中讲实例划分为正负两类的分离超平面,属于判别模型.介绍了感知机的损失函数,利用梯度下降算法求损失函数的极小值.感知机分为原始问题和对偶问题.感知机是一个简单的模型,容易实现,是支持向量机和神经网络的基础.需要注意的是,感知机算法得到的超平面结果不唯一,如果要得到唯一的记过需要增加约束条件,而且如何处线性不可分问题?可以联系第7章支持向量机.感知机是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第3章 k近邻法.md">第3章 k近邻法</div>
    <div class="preview">
        <p>k近邻法(k-nearest neighbor, k-NN)是一种基本分类和回归方法,书中只介绍了其处理分类问题的应用.k近邻法的输入为实例的特征向量,对应于特征空间的点;输出位是你的类别.主要内容包括:多数表决,三要素(k值选择,距离度量,分类策略),实现方法:kd树.k-NN算法简单直观,容易实现.但是算法复杂度很高,大的样本容量性能不佳.k近邻法是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第4章 朴素贝叶斯法.md">第4章 朴素贝叶斯法</div>
    <div class="preview">
        <p>朴素贝叶斯(naïve Bayes)法是给予贝叶斯定理与特征条件独立假设的分类方法(注意与贝叶斯估计(Bayes estimation)概念上的不同).先假设特征条件独立得到联合分布;然后对给定输入x,使用贝叶斯定理求后验概率,并且最大化后验概率(即输出分类y).贝叶斯算法简单易实现,而且效率很好,是一种常用的方法.书中介绍了利用极大似然估计(MLE)和(一种贝叶斯估计)拉普拉斯平滑(Laplace smoothing)来求先验分布和似然分布.极大似然估计和贝叶斯估计最大的不同即是对参数的看法不同,分成了传统学派和贝叶斯派,这方面的内容可以看最后的参考资料.朴素贝叶斯法是生成模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第5章 决策树.md">第5章 决策树</div>
    <div class="preview">
        <p>决策树(decision tree)是一种基本的分类与回归方法.书中主要介绍了分类的应用,是特征对实例进行分类,也可以看作是if-then规则的集合,还可以看做是定义在特征空间与类空间上的条件概率分布.决策树具有可读性,分类速度快的优点.决策树学习3个步骤:特征选择,决策树生成,决策树剪枝.决策树的关键在于特征选择(信息增益,信息增益率,基尼系数),主要算法包括ID3,C4.5和CART.决策树是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第6章 逻辑斯蒂回归与最大熵模型.md">第6章 逻辑斯蒂回归与最大熵模型</div>
    <div class="preview">
        <p>逻辑斯蒂回归(logisitic regression)是统计学习中的经典分类方法.最大熵是概率模型学习的一个准则,推广到分类模型中就是最大熵模型(maximum entropy model).逻辑斯蒂回归和最大熵模型都属于对数线性模型(目标函数都是似然函数,本质都是极大似然估计).最后介绍逻辑斯蒂回归和最大熵模型(归结为似然函数为目标函数的最优化问题)的算法(通常用迭代法求解,而且似然函数都是很好的性质:凸性,有许多算法可以用:IIS,梯度下降,还有更快的牛顿法和拟牛顿法,这部分内容可以查看附录A,附录B和参考资料).逻辑斯蒂回归和最大熵模型都是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第7章 支持向量机.md">第7章 支持向量机</div>
    <div class="preview">
        <p>支持向量机(support vector machine, SVM)是一种二分类模型,定义在特征空间上的间隔最大的线性分类器,与感知机不同(感知机是误分类数最小,结果不唯一);支持向量机的重点是核技巧的运用,可以处理非线性分类的问题.支持向量机的策略是间隔最大化,实质是一个凸二次规划(convex quadratic programming)问题,等价于正则化的合页损失函数的最小化问题,一般转化为其对偶问题求解(利用拉格朗日乘子法和</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第8章 提升方法.md">第8章 提升方法</div>
    <div class="preview">
        <p>提升(boosting)方法是一种常用的统计学习方法,应用广泛而且有效.在分类问题中,它通过改变训练样本的权重,学习多个分类器,并将这些写分类器进行线性组合,提高分类的性能.这章首先介绍提升方法的思路和代表性的提升算法AdaBoost;软后通过训练误差分析探讨AdaBoost为什么能够提高学习精度;并且从前向分步加法模型的角度解释AdaBoost;最后叙述提升方法更具体的实例:提升树(boosting tree).提升方法是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第9章 EM算法及其推广.md">第9章 EM算法及其推广</div>
    <div class="preview">
        <p>EM算法是一种迭代算法,1977年有Dempster缝纫总结提出,用于含有隐变量(hidden variable)的概率模型参数的极大似然估计,或者极大后验概率估计.EM算法的每次迭代由两步组成:E步,求期望(expectation);M步,求极大(maximization).所以这一算法称为期望极大算法(expectation maximization algorithm),简称EM算法.这章首先叙述EM算法,然后讨论EM算法的收敛性;介绍GMM的学习(EM算法的应用);最后叙述EM算法的推广:GEM算法.EM算法在书中的10中算法中有些特殊,它不是生成模型或者判别模型,它是个一般方法,不具有具体模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第10章 隐马尔可夫模型.md">第10章 隐马尔可夫模型</div>
    <div class="preview">
        <p>隐马尔可夫模型(hidden Markov model,HMM)是可用于标注问题的统计学习模型,描述由隐藏的马尔可夫链随机生成观测序列的过程,所以是生成模型.这章首先介绍模型的基本概念,然后分别叙述模型的概率计算方法,学习算法和预测算法.隐马尔可夫模型在语音识别,自然语言处理,生物信息,模式识别等领域有着广泛的应用.隐马尔可夫模型是生成模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第11章 条件随机场.md">第11章 条件随机场</div>
    <div class="preview">
        <p>条件随机场(conditional random field,CRF)是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型,假设输出随机变量构成马尔可夫随机场.可用于不同的预测问题,书中仅论及它在标注问题的应用.因此主要讲述线性链(linear chain)条件随机场,这是问题变成了由输入序列对输出序列的判别模型,形式为对数线性模型,其学习方法通常是MLE或者正则化的MLE.线性链条件随机场应用于标注问题是由Lafferty等人于2001年提出.这章先介绍概率无向图模型;然后叙述CRF的定义和各种表示方法,最后介绍CRF的3个基本问题:概率计算问题,学习问题和预测问题.条件随机场是判别模型.</p>
    </div>
</div>
<div class="list-item">
    <div class="ajax-link forward" data-url="5.李航统计机器学习/第12章 统计学习方法总结.md">第12章 统计学习方法总结</div>
    <div class="preview">
        <p>书中介绍了10种主要的统计学习方法:感知机,k近邻法,朴素贝叶斯法,决策树,逻辑斯蒂回归与最大熵模型,支持向量机,提升方法,EM算法,隐马尔科夫模型和条件随机场.</p>
    </div>
</div>
