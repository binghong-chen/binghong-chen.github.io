## 第1章:机器学习简介
该系列课程包括机器学习所需的数学基础,算法应用,模型及实际案例.干货十足,课程内容包括机器学习简介,机器学习实例操作,Logistic回归分析与神经网络,支持向量机(SVM),降维与矩阵分解,聚类,特征工程,决策树及基于树的集成模型:随机森林,梯度提升决策树(GBDT),推荐系统与广告点击率(CTR)预估,广告点击率(CTR)预估和模型融合.

学习要点
1. 机器学习定义;
2. 机器学习行业应用举例;
3. 机器学习任务:分类,回归,聚类,降维,半监督学习,迁移学习,强化学习;
4. 机器学习算法的组成部分:目标函数(损失函数+正则),优化方法;
5. 模型评估和模型选择:模型复杂度,overfitting,交叉验证,超参数空间,网格搜索…
 
案例:波士顿房价.包含内容——损失函数,L1/L2正则,小二乘,梯度下降/随机梯度下降.
 
课程目标:熟悉机器学习领域的常用术语,了解机器学习在AI环境中的位置.
 

如何选择聚类的分类个数?
半监督学习  根据带标签数据+不带标签数据进行分类(聚类) 监督学习+非监督学习(组合)
实例:波士顿房价模型(13个特征)
(一)线性回归模型
假设房价与输入特征之间是线性关系
相关系数 可以计算每两个变量的相关系数(不仅可以计算y和每个特征的相关系数,还可以计算两个特征之间的相关系数) 14X14的矩阵
相关系数是线性模型的,相关系数为0不一定独立
特征间相关性太强是不好的,有技术消除特征的相关性.(PCA)

怎么求得线性模型的系数?
如何选择线性模型的特征个数?(有可能选择更少的特征,虽然在训练集上误差大了,但是测试误差会变小,泛化能力好)
R2分数 预测值和实际值相关性 越大越好 0~1
选择11个特征时 训练性能不如全部特征,但测试性能好于全部特征
训练性能:0.7408<0.7451
测试性能:0.6917>0.6903

(二)决策树模型
非线性模型


效果好于线性模型,说明房价和特征之间不是线性关系.
模型选择:
    不同模型(线性模型,决策树...)
    不同特征
    决策树 树深度
    ...

泛化能力(generalization)
机器学习任务的一般步骤
• 确定特征
    – 可能是最重要的步骤! (收集训练数据)
• 确实模型(线性模型(正则类型),决策树,SVM)
    – 目标函数
• 模型训练:根据训练数据估计模型参数
    – 优化计算
• 模型评估:利用模型对新样本进行分类
    不好回到 确定特征 或者 确定模型

• 注意:Deep Learning可学习特征
    – 对视觉/语音等非结构化数据尤其重要


损失函数

回归损失
L2损失 
    优点:光滑(导数连续)梯度下降好处理
    缺点:对噪声敏感
L1损失 
    优点:对噪声不敏感
    缺点:不光滑(导数不连续) 
Huber损失
    结合L1损失和L2损失的优点 光滑,对噪声不敏感


分类损失
    0-1损失
    对数损失(log损失)
    指数损失
    合页损失

正则项

为什么要引入正则项(降低结构风险)?
    1.只考虑损失函数的话,可能训练数据的损失很小或者为0,这只能说明模型与训练数据拟合的好
    2.不能代表测试数据或者真实数据就拟合得好(模型的泛化能力不强)
        两种思路:
        1.测试数据(或者真实数据)和训练数据通常假设是来自同分布的独立样本,但只是分布相同,随机变量取值会变化
        2.训练数据中可能会有噪声,模型不应该过分拟合噪声
    3.复杂模型(预测)不稳定:方差大(训练数据有小的变化,得到的模型变化很大 也叫病态模型)
故需要控制模型的复杂度,引入正则项:对复杂模型施加惩罚
模型复杂度与泛化误差的关系通常是U形曲线


常用正则函数
    L2正则
    L1正则
    L0正则(非θ参数的数目,不好优化,常用L1正则代替)


如何求解正则项系数λ?
    老师回答我用 交叉验证


岭回归    L2损失+L2正则
LASSO    L2损失+L1正则
Elastic net(弹性网络)    L2损失+(L2正则+L1正则)
SVM        合页损失+L2正则
SVR          ε-insentive损失+L2正则
L2正则Logistic回归
L1正则Logistic回归    

模型训练(模型求解)
简单模型:
    直接计算 如小数据集上的线性回归模型
复杂模型:
    梯度下降 随机梯度下降(大数据集时,从训练数据中随机选取样本学习) 
    牛顿法 拟牛顿法

模型选择和模型评估
    模型选择:估计不同模型的性能,选出最好的模型    如:线性回归vs决策树
    模型评估:已经选定最终的模型,估计它在新数据上的预测误差

样本足够多,数据分三份
    训练集    估计模型的参数
    校验集    估计模型的预测误差
    测试集    计算最终选定的模型的泛化误差
做竞赛时时看不到测试集,一般我们接触的多的是训练集合校验集

一般没有足够的样本,可以通过重采样技术来模拟校验集 代表:交叉验证和bootstrap的重采样技术
sk-learn 中提供将数据分成训练集和校验集的功能

交叉验证:机器学习中最核心的概念之一
K-折交叉验证

下节课预告
学习环境搭建(所需软件)
Anaconda(Jupter,Python,Numpy,Scipy,Pandas,ScikitLearn,Matplotlib,Seaborn)
实现波士顿房价机器学习项目
多项式拟合例子
    实际模型是一个sin函数,加上一个方差小的高斯噪声
随机采样9个点
    0阶多项式 就是均值 欠拟合
    1阶多项式 一条直线  欠拟合
    3阶多项式
    ...
    9阶多项式 过拟合(训练时每个采样点都精确符合,训练误差为0,但是它把噪声当做正常的因子,
    得到的模型多项式系数的绝对值很大,各项有正有负相互抵消,但是对数据敏感,数据一个小的变化,
    就会使误差被严重放大,对噪声敏感,模型不稳定,方差大,是一个病态模型)

随机采样100个点
    9阶多项式和原始模型拟合得很好 
    所以不能简单说一个模型好或不好,只能说这个模型与问题是匹配的
    需要考虑:样本数,特征维数,数据蕴含的关系的复杂程度 等

正则项系数λ与误差的关系

图像左侧是λ小时,正则项权重小,容易训练出过于复杂的模型,模型容易过拟合
图像右侧是λ大时,正则项权重大,容易训练出过于简单的模型,模型容易欠拟合

结论:当样本量很大时,可以考虑复杂模型,但是当样本量很小时,复杂模型一定会过拟合  
模型复杂度必须要控制得很好,不能太简单,也不能太复杂,需要和问题的复杂度相匹配  
[作业:kaggle上的房价预测问题](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)



House Prices: Advanced Regression Techniques
波士顿房价模型的现代扩展版本

feature engineering 

Advanced regression techniques like random forest and gradient boosting
