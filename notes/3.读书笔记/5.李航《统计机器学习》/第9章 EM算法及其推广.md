## 第9章 EM算法及其推广
EM算法是一种迭代算法,1977年有Dempster缝纫总结提出,用于含有隐变量(hidden variable)的概率模型参数的极大似然估计,或者极大后验概率估计.EM算法的每次迭代由两步组成:E步,求期望(expectation);M步,求极大(maximization).所以这一算法称为期望极大算法(expectation maximization algorithm),简称EM算法.这章首先叙述EM算法,然后讨论EM算法的收敛性;介绍GMM的学习(EM算法的应用);最后叙述EM算法的推广:GEM算法.EM算法在书中的10中算法中有些特殊,它不是生成模型或者判别模型,它是个一般方法,不具有具体模型.

### 9.1 EM算法的引入

#### 9.1.1 EM算法

#### 9.1.2 EM算法的导出

#### 9.1.3 EM算法在非监督学习中的应用

### 9.2 EM算法的收敛性

### 9.3 EM算法在高斯混合模型中的应用

#### 9.3.1 高斯混合模型

#### 9.3.2 高斯混合模型参数估计的EM算法

### 9.4 EM算法的推广

#### 9.4.1 F函数的极大-极大算法

#### 9.4.2 GEM算法

参考资料:
[1. EM算法 本质 为什么要这样做?看起来更加复杂]
[2. 高斯混合模型]
[3. F函数是什么?]