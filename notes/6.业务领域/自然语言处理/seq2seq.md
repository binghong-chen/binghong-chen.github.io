## seq2seq
seq2seq

Sequence-to-Sequence Model

Encoder     Decoder


papers:  
[Neural machine translation by jointly learning to align and translate](https://arxiv.org/abs/1409.0473)
>这篇文章在神经网络 采用编码-解码RNN 做端到端的机器翻译的基础上,使得模型可以在预测下一个词的时候,自动地选择原句子相关的部分作为解码的输入,这也是后来被提为attention机制的内容.该模型的性能在英法语数据的评测上超过了当前使用基于短语的机器翻译系统.
